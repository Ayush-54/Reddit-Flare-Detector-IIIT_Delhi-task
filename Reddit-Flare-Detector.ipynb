{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)\n",
    "reddit = praw.Reddit(client_id='NVyf-I0I6atu2w',\\\n",
    "                     client_secret='Sn1bZ2ID-P5X6hFV-mjt09v0j5c',\\\n",
    "                     user_agent='Testing_api', \\\n",
    "                     username='reddit_testbyayush', \\\n",
    "                     password='password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('finalized_model.sav', 'rb'))\n",
    "subreddit = reddit.subreddit('india')\n",
    "top_subreddit = subreddit.top()\n",
    "top_subreddit = subreddit.top(limit=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flair in flairs:\n",
    "    get_subreddits = subreddit.search(flair, limit=500)\n",
    "\n",
    "for submission in subreddit.top(limit=5):\n",
    "    print(submission.title, submission.url)\n",
    "\n",
    "topics_dict = {\"flair\":[],  \"title\":[],  \"score\":[],  \"id\":[],  \"url\":[],  \"comms_num\": [],  \"created\": [], \"body\":[]}\n",
    "\n",
    "for submission in top_subreddit:\n",
    "    topics_dict[\"flair\"].append(flair)\n",
    "    topics_dict[\"title\"].append(submission.title)\n",
    "    topics_dict[\"score\"].append(submission.score)\n",
    "    topics_dict[\"id\"].append(submission.id)\n",
    "    topics_dict[\"url\"].append(submission.url)\n",
    "    topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "    topics_dict[\"created\"].append(submission.created)\n",
    "    topics_dict[\"body\"].append(submission.selftext)\n",
    "topics_data = pd.DataFrame(topics_dict)\n",
    "print(topics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "_timestamp = topics_data[\"created\"].apply(get_date)\n",
    "topics_data = topics_data.assign(timestamp = _timestamp)\n",
    "print(topics_data)\n",
    "topics_data.to_csv('reddit-india-data.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analysis(input_file):\n",
    "    df = pd.read_csv(input_file, header = 0)\n",
    "    print(df.head())\n",
    "    print(df.count())\n",
    "    print(df.shape)\n",
    "    duplicate_rows_df = df[df.duplicated()]\n",
    "    print(\"number of duplicate rows:\", duplicate_rows_df.shape)\n",
    "    df = df.drop_duplicates()\n",
    "    print(df.head())\n",
    "    print(df.count())\n",
    "    print(df.isnull().sum())\n",
    "    # Dropping the missing values.\n",
    "    df = df.dropna() \n",
    "    print(df.count())\n",
    "    sns.boxplot(x=df[\"comms_num\"])\n",
    "    # Plotting a scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    ax.scatter(df[\"id\"],df[\"comms_num\"])\n",
    "    ax.set_xlabel(\"id\")\n",
    "    ax.set_ylabel(\"comms_num\")\n",
    "    plt.show()\n",
    "    # Plotting a Histogram\n",
    "    df.comms_num.value_counts().nlargest().plot(kind='bar', figsize=(10,5))\n",
    "    plt.title(\"Comments vs id\")\n",
    "    plt.ylabel(\"Number of comments\")\n",
    "    plt.xlabel(\"id\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X,y):\n",
    " \n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
    "\n",
    "  print(\"Results of Naive Bayes Classifier\")\n",
    "  nb_classifier(X_train, X_test, y_train, y_test)\n",
    "  print(\"Results of Random Forest\")\n",
    "  randomforest(X_train, X_test, y_train, y_test)\n",
    "  print(\"Results of MLP Classifier\")\n",
    "  mlpclassifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "  from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "  nb = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', MultinomialNB()),\n",
    "                ])\n",
    "  nb.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = nb.predict(X_test)\n",
    "\n",
    "  print('accuracy is %s' % accuracy_score(y_pred, y_test),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  \n",
    "  ranfor = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', RandomForestClassifier(n_estimators = 1000, random_state = 42)),\n",
    "                 ])\n",
    "  ranfor.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = ranfor.predict(X_test)\n",
    "\n",
    "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlpclassifier(X_train, X_test, y_train, y_test):\n",
    "  \n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  \n",
    "  mlp = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', MLPClassifier(hidden_layer_sizes=(30,30,30))),\n",
    "                 ])\n",
    "  mlp.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = mlp.predict(X_test)\n",
    "\n",
    "  print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_flair(id):\n",
    "    submission = reddit.submission(id=id)\n",
    "    topics_dict['combine'] = submission.title + submission.url\n",
    "    return loaded_model.predict([topics_dict['combine']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_flair(id):\n",
    "    \n",
    "    submission = reddit.submission(id=id)\n",
    "    url = input(\"Enter the url of the article whose flare you want to find:\")\n",
    "    return loaded_model.predict([url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"reddit-india-data.csv\"\n",
    "data_analysis(file_name)\n",
    "\n",
    "X = topics_data.title\n",
    "Y = topics_data.body\n",
    "Z = topics_data.url\n",
    "F = topics_data.flair\n",
    "print(\"Flair Detection using Title as Feature\")\n",
    "train_test(X,F)\n",
    "print(\"Flair Detection using Body as Feature\")\n",
    "train_test(Y,F)\n",
    "print(\"Flair Detection using URL as Feature\")\n",
    "train_test(Z,F)\n",
    "\n",
    "subreddit = reddit.subreddit('india')\n",
    "print('The flares of first five headings are:')\n",
    "for submission in subreddit.top(limit=10):\n",
    "    print(detect_flair(submission.id))\n",
    "\n",
    "for submission in subreddit.top(limit=1):\n",
    "    print(find_flair(submission.id))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
